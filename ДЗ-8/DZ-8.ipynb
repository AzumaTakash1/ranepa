{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089bdc02",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'horse-colic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 368\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_no_missing\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;66;03m# Теперь df_no_missing — датафрейм БЕЗ пропусков,\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;66;03m# его можно использовать дальше для моделей и т.п.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;66;03m# При желании можно вернуть его из функции:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Если df пока нет, можно загрузить свои данные, например так:\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhorse-colic.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# тут заменить на свой путь и параметры\u001b[39;00m\n\u001b[0;32m    369\u001b[0m run_homework_analysis(df)\n",
      "File \u001b[1;32mc:\\users\\79629\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\79629\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\users\\79629\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\79629\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\users\\79629\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'horse-colic.csv'"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ИМПОРТ БИБЛИОТЕК\n",
    "# ================================================\n",
    " \n",
    "import pandas as pd   # основная библиотека для работы с таблицами\n",
    "import numpy as np    # библиотека для численных вычислений\n",
    " \n",
    "# Эти две библиотеки не обязательны, но полезны для визуализации выбросов\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    " \n",
    "# ================================================\n",
    "# НАСТРОЙКИ: КАКИЕ СТОЛБЦЫ БУДЕМ ИЗУЧАТЬ\n",
    "# ================================================\n",
    " \n",
    "# Здесь мы явно указываем, какие 8 колонок берём для анализа.\n",
    "# ❗ ЕСЛИ у тебя в df другие названия колонок,\n",
    "#    просто поменяй элементы списков ниже.\n",
    " \n",
    "numeric_cols = [\n",
    "    \"rectal_temp\",         # ректальная температура (число)\n",
    "    \"pulse\",               # пульс (число)\n",
    "    \"respiratory_rate\",    # частота дыхания (число)\n",
    "    \"packed_cell_volume\"   # гематокрит (число)\n",
    "]\n",
    " \n",
    "categorical_cols = [\n",
    "    \"pain\",                # уровень боли (категориальная)\n",
    "    \"abdominal_distension\",# вздутие живота (категориальная)\n",
    "    \"outcome\",             # исход (категориальная)\n",
    "    \"surgery\"              # была ли операция (категориальная)\n",
    "]\n",
    " \n",
    "selected_cols = numeric_cols + categorical_cols\n",
    " \n",
    " \n",
    "# ================================================\n",
    "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ\n",
    "# ================================================\n",
    " \n",
    "def select_columns(df: pd.DataFrame,\n",
    "                   cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Функция выбирает из исходного датафрейма только нужные столбцы.\n",
    " \n",
    "    df   - исходный датафрейм со всеми данными\n",
    "    cols - список названий столбцов, которые нужны для анализа\n",
    " \n",
    "    Возвращает новый датафрейм только с этими столбцами.\n",
    "    \"\"\"\n",
    "    # .copy() — делаем копию, чтобы не портить исходный df\n",
    "    df_sel = df[cols].copy()\n",
    "    return df_sel\n",
    " \n",
    " \n",
    "def basic_stats_numeric(df: pd.DataFrame,\n",
    "                        numeric_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считает базовые статистики для ЧИСЛОВЫХ столбцов.\n",
    " \n",
    "    Для каждого столбца получаем:\n",
    "    - count (сколько наблюдений, не NaN)\n",
    "    - mean (среднее)\n",
    "    - std (стандартное отклонение)\n",
    "    - min, max\n",
    "    - 25%, 50% (медиана), 75% квартили\n",
    "    - моду (mode)\n",
    " \n",
    "    Возвращает датафрейм с описанием (describe),\n",
    "    а моду печатает отдельно.\n",
    "    \"\"\"\n",
    "    print(\"=== Базовые статистики для числовых столбцов ===\\n\")\n",
    " \n",
    "    # describe() сразу считает основные статистики для всех числовых колонок\n",
    "    desc = df[numeric_cols].describe().T  # .T — транспонируем, чтобы столбцы были строками\n",
    "    print(desc, \"\\n\")\n",
    " \n",
    "    # Считаем моду (наиболее часто встречающееся значение) по каждому столбцу\n",
    "    print(\"Моды для числовых столбцов:\")\n",
    "    for col in numeric_cols:\n",
    "        mode_series = df[col].mode(dropna=True)\n",
    "        if mode_series.empty:\n",
    "            print(f\"  {col}: мода не определена (нет данных)\")\n",
    "        else:\n",
    "            # mode() может вернуть несколько значений, возьмём первое\n",
    "            print(f\"  {col}: мода = {mode_series.iloc[0]}\")\n",
    "    print()\n",
    " \n",
    "    return desc\n",
    " \n",
    " \n",
    "def basic_stats_categorical(df: pd.DataFrame,\n",
    "                            categorical_cols: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Считает базовые статистики для КАТЕГОРИАЛЬНЫХ столбцов.\n",
    " \n",
    "    Для каждой категории:\n",
    "    - выводим количество различных значений (nunique)\n",
    "    - выводим частоты значений (value_counts)\n",
    "    - находим моду (самое частое значение)\n",
    "    \"\"\"\n",
    "    print(\"=== Базовые статистики для категориальных столбцов ===\\n\")\n",
    " \n",
    "    for col in categorical_cols:\n",
    "        print(f\"Столбец: {col}\")\n",
    "        print(f\"  Количество уникальных значений: {df[col].nunique(dropna=True)}\")\n",
    " \n",
    "        # value_counts показывает, сколько раз встречается каждое значение\n",
    "        print(\"  Частоты значений (включая NaN):\")\n",
    "        print(df[col].value_counts(dropna=False))\n",
    " \n",
    "        # Мода\n",
    "        mode_series = df[col].mode(dropna=True)\n",
    "        if mode_series.empty:\n",
    "            print(\"  Мода: отсутствует (нет данных)\")\n",
    "        else:\n",
    "            print(f\"  Мода: {mode_series.iloc[0]}\")\n",
    "        print(\"-\" * 40)\n",
    " \n",
    " \n",
    "def find_outliers_iqr(series: pd.Series) -> tuple[pd.Series, float, float]:\n",
    "    \"\"\"\n",
    "    Ищем выбросы в одном числовом столбце с помощью правила IQR.\n",
    " \n",
    "    IQR (interquartile range) = Q3 - Q1\n",
    "    Нижняя граница = Q1 - 1.5 * IQR\n",
    "    Верхняя граница = Q3 + 1.5 * IQR\n",
    " \n",
    "    Всё, что < нижней границы или > верхней границы, считаем выбросами.\n",
    " \n",
    "    Возвращаем:\n",
    "    - булеву маску (True, где выброс),\n",
    "    - нижнюю границу,\n",
    "    - верхнюю границу.\n",
    "    \"\"\"\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    " \n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    " \n",
    "    # mask = True там, где значение < lower_bound или > upper_bound\n",
    "    mask = (series < lower_bound) | (series > upper_bound)\n",
    " \n",
    "    return mask, lower_bound, upper_bound\n",
    " \n",
    " \n",
    "def analyze_outliers(df: pd.DataFrame,\n",
    "                     numeric_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Для каждого числового столбца:\n",
    "    - находим выбросы по правилу IQR\n",
    "    - считаем их количество\n",
    "    - выводим границы\n",
    " \n",
    "    Возвращаем датафрейм с суммарной информацией по выбросам:\n",
    "    столбец, количество выбросов, доля выбросов.\n",
    "    \"\"\"\n",
    "    print(\"=== Анализ выбросов (IQR-метод) для числовых столбцов ===\\n\")\n",
    " \n",
    "    rows = []\n",
    " \n",
    "    for col in numeric_cols:\n",
    "        series = df[col].dropna()  # игнорируем пропуски при поиске выбросов\n",
    "        mask, lower, upper = find_outliers_iqr(series)\n",
    " \n",
    "        n_outliers = mask.sum()  # сколько True\n",
    "        n_total = series.shape[0]\n",
    "        share = n_outliers / n_total if n_total > 0 else 0\n",
    " \n",
    "        print(f\"Столбец: {col}\")\n",
    "        print(f\"  Нижняя граница: {lower:.3f}\")\n",
    "        print(f\"  Верхняя граница: {upper:.3f}\")\n",
    "        print(f\"  Количество выбросов: {n_outliers} из {n_total} ({share:.2%})\")\n",
    " \n",
    "        # Можно при желании посмотреть сами выбросы:\n",
    "        # print(series[mask])\n",
    " \n",
    "        print(\"-\" * 40)\n",
    " \n",
    "        rows.append({\n",
    "            \"column\": col,\n",
    "            \"n_outliers\": n_outliers,\n",
    "            \"n_non_null\": n_total,\n",
    "            \"share_outliers\": share\n",
    "        })\n",
    " \n",
    "    # Делаем из списка словарей итоговый датафрейм\n",
    "    outliers_summary = pd.DataFrame(rows)\n",
    "    return outliers_summary\n",
    " \n",
    " \n",
    "def plot_outliers_boxplots(df: pd.DataFrame,\n",
    "                           numeric_cols: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Дополнительная функция: рисуем boxplot'ы для числовых столбцов,\n",
    "    чтобы визуально увидеть выбросы.\n",
    " \n",
    "    Это НЕ обязательно для ДЗ, но полезно для понимания.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    " \n",
    "    # Перестраиваем данные в \"длинный\" формат для удобства рисования\n",
    "    df_long = df[numeric_cols].melt(var_name=\"column\", value_name=\"value\")\n",
    " \n",
    "    sns.boxplot(data=df_long, x=\"column\", y=\"value\")\n",
    "    plt.title(\"Boxplot для числовых столбцов (выбросы видны как точки вне усов)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "def missing_values_report(df: pd.DataFrame,\n",
    "                          cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считает количество пропусков (NaN) по выбранным столбцам.\n",
    " \n",
    "    Возвращает датафрейм с:\n",
    "    - column      — имя столбца\n",
    "    - n_missing   — сколько пропусков\n",
    "    - share_missing — доля пропусков\n",
    "    \"\"\"\n",
    "    print(\"=== Отчёт по пропускам (NaN) ===\\n\")\n",
    " \n",
    "    rows = []\n",
    " \n",
    "    for col in cols:\n",
    "        n_missing = df[col].isna().sum()\n",
    "        n_total = df[col].shape[0]\n",
    "        share = n_missing / n_total if n_total > 0 else 0\n",
    " \n",
    "        print(f\"{col}: пропусков {n_missing} из {n_total} ({share:.2%})\")\n",
    " \n",
    "        rows.append({\n",
    "            \"column\": col,\n",
    "            \"n_missing\": n_missing,\n",
    "            \"n_total\": n_total,\n",
    "            \"share_missing\": share\n",
    "        })\n",
    " \n",
    "    print()\n",
    "    return pd.DataFrame(rows)\n",
    " \n",
    " \n",
    "def fill_missing_values(df: pd.DataFrame,\n",
    "                        numeric_cols: list[str],\n",
    "                        categorical_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создаёт НОВЫЙ датафрейм, где НЕТ пропусков.\n",
    " \n",
    "    Принята следующая стратегия (её потом можно описать в отчёте):\n",
    "    - для числовых столбцов: заполняем пропуски МЕДИАНОЙ\n",
    "      (устойчива к выбросам, хороший дефолтный выбор)\n",
    "    - для категориальных столбцов: заполняем пропуски МОДОЙ\n",
    "      (самая частая категория)\n",
    " \n",
    "    Возвращает df_filled — копию df без пропусков.\n",
    "    \"\"\"\n",
    "    df_filled = df.copy()\n",
    " \n",
    "    # Числовые\n",
    "    for col in numeric_cols:\n",
    "        median_value = df_filled[col].median()\n",
    "        print(f\"Заполняем пропуски в числовом столбце {col} медианой = {median_value}\")\n",
    "        df_filled[col] = df_filled[col].fillna(median_value)\n",
    " \n",
    "    # Категориальные\n",
    "    for col in categorical_cols:\n",
    "        mode_series = df_filled[col].mode(dropna=True)\n",
    "        if mode_series.empty:\n",
    "            # если вдруг все значения NaN — можно придумать спец. категорию\n",
    "            fill_value = \"Unknown\"\n",
    "            print(f\"Все значения в {col} пропущены, заполняем 'Unknown'\")\n",
    "        else:\n",
    "            fill_value = mode_series.iloc[0]\n",
    "            print(f\"Заполняем пропуски в категориальном столбце {col} модой = {fill_value}\")\n",
    " \n",
    "        df_filled[col] = df_filled[col].fillna(fill_value)\n",
    " \n",
    "    print(\"\\nВсе пропуски заполнены.\")\n",
    "    return df_filled\n",
    " \n",
    " \n",
    "# ================================================\n",
    "# ОСНОВНОЙ \"ОРКЕСТРАТОР\" ДЛЯ ДЗ\n",
    "# ================================================\n",
    " \n",
    "def run_homework_analysis(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Основная функция, которая запускает все шаги домашнего задания:\n",
    " \n",
    "    1) Базовое изучение: выбор 8 колонок, расчёт базовых метрик.\n",
    "    2) Работа с выбросами: поиск выбросов в числовых столбцах.\n",
    "    3) Работа с пропусками: подсчёт пропусков, заполнение и получение df без NaN.\n",
    " \n",
    "    df — датафрейм со всеми исходными данными (из ноутбука).\n",
    "    \"\"\"\n",
    " \n",
    "    # ---------- Задание 1. Базовое изучение ----------\n",
    "    print(\"\\n========== ЗАДАНИЕ 1: БАЗОВОЕ ИЗУЧЕНИЕ ==========\\n\")\n",
    " \n",
    "    df_sel = select_columns(df, selected_cols)\n",
    " \n",
    "    # Базовые статистики для числовых\n",
    "    desc_numeric = basic_stats_numeric(df_sel, numeric_cols)\n",
    " \n",
    "    # Базовые статистики для категориальных\n",
    "    basic_stats_categorical(df_sel, categorical_cols)\n",
    " \n",
    "    # Здесь, в отдельной markdown-ячейке в ноутбуке,\n",
    "    # можно кратко описать результаты: диапазоны, медианы,\n",
    "    # какие значения категорий чаще встречаются и т.д.\n",
    " \n",
    "    # ---------- Задание 2. Работа с выбросами ----------\n",
    "    print(\"\\n========== ЗАДАНИЕ 2: РАБОТА С ВЫБРОСАМИ ==========\\n\")\n",
    " \n",
    "    outliers_summary = analyze_outliers(df_sel, numeric_cols)\n",
    " \n",
    "    print(\"\\nСводная таблица по выбросам:\")\n",
    "    print(outliers_summary)\n",
    " \n",
    "    # Дополнительно можно визуализировать выбросы\n",
    "    # (по желанию, не обязательно для сдачи ДЗ):\n",
    "    # plot_outliers_boxplots(df_sel, numeric_cols)\n",
    " \n",
    "    # В отдельной markdown-ячейке:\n",
    "    # - сформулировать гипотезы, откуда взялись выбросы\n",
    "    #   (ошибки ввода, редкие тяжёлые состояния и т.п.)\n",
    "    # - принять решение: оставляем, обрезаем, заменяем и т.д.\n",
    "    # В этом коде мы НИЧЕГО с выбросами не делаем автоматически,\n",
    "    # только считаем и показываем.\n",
    " \n",
    "    # ---------- Задание 3. Работа с пропусками ----------\n",
    "    print(\"\\n========== ЗАДАНИЕ 3: РАБОТА С ПРОПУСКАМИ ==========\\n\")\n",
    " \n",
    "    # 1) Считаем пропуски\n",
    "    missing_report = missing_values_report(df_sel, selected_cols)\n",
    "    print(\"Таблица с пропусками:\")\n",
    "    print(missing_report, \"\\n\")\n",
    " \n",
    "    # 2) Заполняем пропуски по выбранной стратегии (медиана / мода)\n",
    "    df_no_missing = fill_missing_values(df_sel, numeric_cols, categorical_cols)\n",
    " \n",
    "    # Проверим, что пропусков действительно нет\n",
    "    print(\"\\nПроверяем, остались ли пропуски:\")\n",
    "    print(df_no_missing.isna().sum())\n",
    " \n",
    "    # Теперь df_no_missing — датафрейм БЕЗ пропусков,\n",
    "    # его можно использовать дальше для моделей и т.п.\n",
    "    # При желании можно вернуть его из функции:\n",
    "    # return df_no_missing\n",
    " \n",
    " \n",
    "# ================================================\n",
    "# ПРИМЕР ЗАПУСКА В НОУТБУКЕ\n",
    "# ================================================\n",
    " \n",
    "# Предполагаем, что в Базовые_Понятния.ipynb у тебя уже есть df.\n",
    "# Тогда достаточно вызвать:\n",
    "#\n",
    "# run_homework_analysis(df)\n",
    "#\n",
    "# Если df пока нет, можно загрузить свои данные, например так:\n",
    "#\n",
    "df = pd.read_csv(\"horse-colic.csv\")  # тут заменить на свой путь и параметры\n",
    "run_homework_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef452ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
